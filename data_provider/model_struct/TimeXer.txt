########## Parameters number for all 3.09 M  #########
Parameter: en_embedding.glb_token, Shape: torch.Size([1, 1, 1, 512])
Parameter: en_embedding.value_embedding.weight, Shape: torch.Size([512, 16])
Parameter: ex_embedding.value_embedding.weight, Shape: torch.Size([512, 30])
Parameter: ex_embedding.value_embedding.bias, Shape: torch.Size([512])
Parameter: encoder.layers.0.self_attention.query_projection.weight, Shape: torch.Size([512, 512])
Parameter: encoder.layers.0.self_attention.query_projection.bias, Shape: torch.Size([512])
Parameter: encoder.layers.0.self_attention.key_projection.weight, Shape: torch.Size([512, 512])
Parameter: encoder.layers.0.self_attention.key_projection.bias, Shape: torch.Size([512])
Parameter: encoder.layers.0.self_attention.value_projection.weight, Shape: torch.Size([512, 512])
Parameter: encoder.layers.0.self_attention.value_projection.bias, Shape: torch.Size([512])
Parameter: encoder.layers.0.self_attention.out_projection.weight, Shape: torch.Size([512, 512])
Parameter: encoder.layers.0.self_attention.out_projection.bias, Shape: torch.Size([512])
Parameter: encoder.layers.0.cross_attention.query_projection.weight, Shape: torch.Size([512, 512])
Parameter: encoder.layers.0.cross_attention.query_projection.bias, Shape: torch.Size([512])
Parameter: encoder.layers.0.cross_attention.key_projection.weight, Shape: torch.Size([512, 512])
Parameter: encoder.layers.0.cross_attention.key_projection.bias, Shape: torch.Size([512])
Parameter: encoder.layers.0.cross_attention.value_projection.weight, Shape: torch.Size([512, 512])
Parameter: encoder.layers.0.cross_attention.value_projection.bias, Shape: torch.Size([512])
Parameter: encoder.layers.0.cross_attention.out_projection.weight, Shape: torch.Size([512, 512])
Parameter: encoder.layers.0.cross_attention.out_projection.bias, Shape: torch.Size([512])
Parameter: encoder.layers.0.conv1.weight, Shape: torch.Size([1024, 512, 1])
Parameter: encoder.layers.0.conv1.bias, Shape: torch.Size([1024])
Parameter: encoder.layers.0.conv2.weight, Shape: torch.Size([512, 1024, 1])
Parameter: encoder.layers.0.conv2.bias, Shape: torch.Size([512])
Parameter: encoder.layers.0.norm1.weight, Shape: torch.Size([512])
Parameter: encoder.layers.0.norm1.bias, Shape: torch.Size([512])
Parameter: encoder.layers.0.norm2.weight, Shape: torch.Size([512])
Parameter: encoder.layers.0.norm2.bias, Shape: torch.Size([512])
Parameter: encoder.layers.0.norm3.weight, Shape: torch.Size([512])
Parameter: encoder.layers.0.norm3.bias, Shape: torch.Size([512])
Parameter: encoder.norm.weight, Shape: torch.Size([512])
Parameter: encoder.norm.bias, Shape: torch.Size([512])
Parameter: head.linear.weight, Shape: torch.Size([30, 1024])
Parameter: head.linear.bias, Shape: torch.Size([30])
Parameter: reconstruction_head.linear.weight, Shape: torch.Size([30, 1024])
Parameter: reconstruction_head.linear.bias, Shape: torch.Size([30])