########## Parameters number for all 3.10 M  #########
Parameter: in_layer.weight, Shape: torch.Size([512, 16])
Parameter: in_layer.bias, Shape: torch.Size([512])
Parameter: encoder.attn_layers.0.attention.query_projection.weight, Shape: torch.Size([512, 512])
Parameter: encoder.attn_layers.0.attention.query_projection.bias, Shape: torch.Size([512])
Parameter: encoder.attn_layers.0.attention.key_projection.weight, Shape: torch.Size([512, 512])
Parameter: encoder.attn_layers.0.attention.key_projection.bias, Shape: torch.Size([512])
Parameter: encoder.attn_layers.0.attention.value_projection.weight, Shape: torch.Size([512, 512])
Parameter: encoder.attn_layers.0.attention.value_projection.bias, Shape: torch.Size([512])
Parameter: encoder.attn_layers.0.attention.out_projection.weight, Shape: torch.Size([512, 512])
Parameter: encoder.attn_layers.0.attention.out_projection.bias, Shape: torch.Size([512])
Parameter: encoder.attn_layers.0.conv1.weight, Shape: torch.Size([2048, 512, 1])
Parameter: encoder.attn_layers.0.conv1.bias, Shape: torch.Size([2048])
Parameter: encoder.attn_layers.0.conv2.weight, Shape: torch.Size([512, 2048, 1])
Parameter: encoder.attn_layers.0.conv2.bias, Shape: torch.Size([512])
Parameter: encoder.attn_layers.0.norm1.weight, Shape: torch.Size([512])
Parameter: encoder.attn_layers.0.norm1.bias, Shape: torch.Size([512])
Parameter: encoder.attn_layers.0.norm2.weight, Shape: torch.Size([512])
Parameter: encoder.attn_layers.0.norm2.bias, Shape: torch.Size([512])
Parameter: encoder.norm.weight, Shape: torch.Size([512])
Parameter: encoder.norm.bias, Shape: torch.Size([512])
Parameter: out_layer.weight, Shape: torch.Size([30, 1536])
Parameter: out_layer.bias, Shape: torch.Size([30])
Parameter: reconstruction_head.weight, Shape: torch.Size([30, 1536])
Parameter: reconstruction_head.bias, Shape: torch.Size([30])